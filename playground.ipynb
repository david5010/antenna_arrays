{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb5d3d704b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.FF_1H import *\n",
    "import torch\n",
    "from main import *\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.Standard_Norm import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12131.30566186,   -753.54752103, -30103.19578924, ...,\n",
       "       -16921.3155718 ,  -3201.28804094, -22758.90653479])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = np.load('data/large/YZ_Large_70.npz')['data']\n",
    "training[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cost = training[:,-1]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_cost.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('scaler.pkl', 'wb') as file:\n",
    "#     pickle.dump(scaler, file)\n",
    "with open('scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.1745, Test Loss: 0.0659\n",
      "Epoch 2 - Train Loss: 0.0516, Test Loss: 0.0558\n",
      "Epoch 3 - Train Loss: 0.0346, Test Loss: 0.0266\n",
      "Epoch 4 - Train Loss: 0.0264, Test Loss: 0.0219\n",
      "Epoch 5 - Train Loss: 0.0214, Test Loss: 0.0194\n",
      "Epoch 6 - Train Loss: 0.0194, Test Loss: 0.0173\n",
      "Epoch 7 - Train Loss: 0.0177, Test Loss: 0.0152\n",
      "Epoch 8 - Train Loss: 0.0164, Test Loss: 0.0180\n",
      "Epoch 9 - Train Loss: 0.0165, Test Loss: 0.0134\n",
      "Epoch 10 - Train Loss: 0.0150, Test Loss: 0.0129\n",
      "Epoch 11 - Train Loss: 0.0153, Test Loss: 0.0134\n",
      "Epoch 12 - Train Loss: 0.0142, Test Loss: 0.0200\n",
      "Epoch 13 - Train Loss: 0.0142, Test Loss: 0.0117\n",
      "Epoch 14 - Train Loss: 0.0139, Test Loss: 0.0236\n",
      "Epoch 15 - Train Loss: 0.0134, Test Loss: 0.0113\n",
      "Epoch 16 - Train Loss: 0.0132, Test Loss: 0.0148\n",
      "Epoch 17 - Train Loss: 0.0132, Test Loss: 0.0131\n",
      "Epoch 18 - Train Loss: 0.0127, Test Loss: 0.0108\n",
      "Epoch 19 - Train Loss: 0.0126, Test Loss: 0.0171\n",
      "Epoch 20 - Train Loss: 0.0120, Test Loss: 0.0128\n",
      "Epoch 21 - Train Loss: 0.0126, Test Loss: 0.0122\n",
      "Epoch 22 - Train Loss: 0.0124, Test Loss: 0.0186\n",
      "Epoch 23 - Train Loss: 0.0118, Test Loss: 0.0113\n",
      "Epoch 24 - Train Loss: 0.0117, Test Loss: 0.0109\n",
      "Epoch 25 - Train Loss: 0.0120, Test Loss: 0.0140\n",
      "Epoch 26 - Train Loss: 0.0117, Test Loss: 0.0120\n",
      "Epoch 27 - Train Loss: 0.0116, Test Loss: 0.0120\n",
      "Epoch 28 - Train Loss: 0.0112, Test Loss: 0.0108\n",
      "Epoch 29 - Train Loss: 0.0116, Test Loss: 0.0164\n",
      "Epoch 30 - Train Loss: 0.0110, Test Loss: 0.0116\n",
      "Epoch 31 - Train Loss: 0.0110, Test Loss: 0.0129\n",
      "Epoch 32 - Train Loss: 0.0108, Test Loss: 0.0106\n",
      "Epoch 33 - Train Loss: 0.0107, Test Loss: 0.0095\n",
      "Epoch 34 - Train Loss: 0.0105, Test Loss: 0.0102\n",
      "Epoch 35 - Train Loss: 0.0105, Test Loss: 0.0103\n",
      "Epoch 36 - Train Loss: 0.0101, Test Loss: 0.0228\n",
      "Epoch 37 - Train Loss: 0.0101, Test Loss: 0.0096\n",
      "Epoch 38 - Train Loss: 0.0105, Test Loss: 0.0102\n",
      "Epoch 39 - Train Loss: 0.0100, Test Loss: 0.0097\n",
      "Epoch 40 - Train Loss: 0.0098, Test Loss: 0.0117\n",
      "Epoch 41 - Train Loss: 0.0099, Test Loss: 0.0121\n",
      "Epoch 42 - Train Loss: 0.0099, Test Loss: 0.0131\n",
      "Epoch 43 - Train Loss: 0.0098, Test Loss: 0.0139\n",
      "Epoch 44 - Train Loss: 0.0097, Test Loss: 0.0106\n",
      "Epoch 45 - Train Loss: 0.0096, Test Loss: 0.0120\n",
      "Epoch 46 - Train Loss: 0.0095, Test Loss: 0.0082\n",
      "Epoch 47 - Train Loss: 0.0094, Test Loss: 0.0097\n",
      "Epoch 48 - Train Loss: 0.0094, Test Loss: 0.0085\n",
      "Epoch 49 - Train Loss: 0.0093, Test Loss: 0.0101\n",
      "Epoch 50 - Train Loss: 0.0094, Test Loss: 0.0094\n",
      "Epoch 51 - Train Loss: 0.0092, Test Loss: 0.0088\n",
      "Epoch 52 - Train Loss: 0.0089, Test Loss: 0.0090\n",
      "Epoch 53 - Train Loss: 0.0095, Test Loss: 0.0087\n",
      "Epoch 54 - Train Loss: 0.0091, Test Loss: 0.0078\n",
      "Epoch 55 - Train Loss: 0.0087, Test Loss: 0.0104\n",
      "Epoch 56 - Train Loss: 0.0089, Test Loss: 0.0084\n",
      "Epoch 57 - Train Loss: 0.0089, Test Loss: 0.0086\n",
      "Epoch 58 - Train Loss: 0.0087, Test Loss: 0.0076\n",
      "Epoch 59 - Train Loss: 0.0089, Test Loss: 0.0102\n",
      "Epoch 60 - Train Loss: 0.0088, Test Loss: 0.0091\n",
      "Epoch 61 - Train Loss: 0.0087, Test Loss: 0.0081\n",
      "Epoch 62 - Train Loss: 0.0089, Test Loss: 0.0076\n",
      "Epoch 63 - Train Loss: 0.0087, Test Loss: 0.0085\n",
      "Epoch 64 - Train Loss: 0.0088, Test Loss: 0.0084\n",
      "Epoch 65 - Train Loss: 0.0086, Test Loss: 0.0086\n",
      "Epoch 66 - Train Loss: 0.0086, Test Loss: 0.0075\n",
      "Epoch 67 - Train Loss: 0.0086, Test Loss: 0.0077\n",
      "Epoch 68 - Train Loss: 0.0083, Test Loss: 0.0075\n",
      "Epoch 69 - Train Loss: 0.0081, Test Loss: 0.0077\n",
      "Epoch 70 - Train Loss: 0.0087, Test Loss: 0.0125\n",
      "Epoch 71 - Train Loss: 0.0082, Test Loss: 0.0073\n",
      "Epoch 72 - Train Loss: 0.0084, Test Loss: 0.0106\n",
      "Epoch 73 - Train Loss: 0.0081, Test Loss: 0.0080\n",
      "Epoch 74 - Train Loss: 0.0085, Test Loss: 0.0087\n",
      "Epoch 75 - Train Loss: 0.0083, Test Loss: 0.0077\n",
      "Epoch 76 - Train Loss: 0.0082, Test Loss: 0.0074\n",
      "Epoch 77 - Train Loss: 0.0081, Test Loss: 0.0073\n",
      "Epoch 78 - Train Loss: 0.0082, Test Loss: 0.0072\n",
      "Epoch 79 - Train Loss: 0.0082, Test Loss: 0.0083\n",
      "Epoch 80 - Train Loss: 0.0081, Test Loss: 0.0096\n",
      "Epoch 81 - Train Loss: 0.0082, Test Loss: 0.0076\n",
      "Epoch 82 - Train Loss: 0.0080, Test Loss: 0.0084\n",
      "Epoch 83 - Train Loss: 0.0082, Test Loss: 0.0078\n",
      "Epoch 84 - Train Loss: 0.0080, Test Loss: 0.0087\n",
      "Epoch 85 - Train Loss: 0.0081, Test Loss: 0.0089\n",
      "Epoch 86 - Train Loss: 0.0080, Test Loss: 0.0093\n",
      "Epoch 87 - Train Loss: 0.0079, Test Loss: 0.0076\n",
      "Epoch 88 - Train Loss: 0.0080, Test Loss: 0.0080\n",
      "Epoch 89 - Train Loss: 0.0079, Test Loss: 0.0082\n",
      "Epoch 90 - Train Loss: 0.0079, Test Loss: 0.0075\n",
      "Epoch 91 - Train Loss: 0.0077, Test Loss: 0.0074\n",
      "Epoch 92 - Train Loss: 0.0078, Test Loss: 0.0072\n",
      "Epoch 93 - Train Loss: 0.0079, Test Loss: 0.0093\n",
      "Epoch 94 - Train Loss: 0.0080, Test Loss: 0.0069\n",
      "Epoch 95 - Train Loss: 0.0078, Test Loss: 0.0071\n",
      "Epoch 96 - Train Loss: 0.0081, Test Loss: 0.0092\n",
      "Epoch 97 - Train Loss: 0.0076, Test Loss: 0.0075\n",
      "Epoch 98 - Train Loss: 0.0078, Test Loss: 0.0092\n",
      "Epoch 99 - Train Loss: 0.0077, Test Loss: 0.0072\n",
      "Epoch 100 - Train Loss: 0.0077, Test Loss: 0.0072\n"
     ]
    }
   ],
   "source": [
    "# train_tensor = norm_scale.transform(torch.from_numpy(np.load('data/large/YZ_Large_70.npz')['data']))\n",
    "# test_tensor = norm_scale.transform(torch.from_numpy(np.load('data/large/YZ_Large_30.npz')['data']))\n",
    "train_loader = DataLoader(AntDataset('data/large/scaled_cost/YZ_Large_70_Cost_Scaled.npz'), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(AntDataset('data/large/scaled_cost/YZ_Large_30_Cost_Scaled.npz'), batch_size=64, shuffle=True)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = NN2(2048, 1, 8, 8, nn.ReLU).to(device)\n",
    "lr = 1e-4\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "epoch = 100\n",
    "train_loss, test_loss = train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, epoch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label = 'Train Loss')\n",
    "plt.plot(test_loss, label = 'Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define and train your PyTorch model\n",
    "# ... Train and optimize the model ...\n",
    "\n",
    "# Save the model's state dictionary or the entire model\n",
    "torch.save(model.state_dict(), 'NN2_CostScaled_8_8_ReLU.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv_file(file_path):\n",
    "    # Load the CSV file using pandas\n",
    "    data_frame = pd.read_csv(file_path, header=None)\n",
    "\n",
    "    # Extract the values and reshape into a numpy array\n",
    "    array_data = data_frame.values.reshape(-1)[:1024]\n",
    "\n",
    "    # Create the final numpy array of length 1024, padded with zeros if necessary\n",
    "    final_array = np.zeros(1024)\n",
    "    final_array[:array_data.shape[0]] = array_data\n",
    "\n",
    "    return final_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape0 = np.hstack((process_csv_file('check_shapes/shape 0/Given Yant0.csv'), process_csv_file('check_shapes/shape 0/Given Zant0.csv')))\n",
    "shape0_opt = np.hstack((process_csv_file('check_shapes/shape 0/Optimized Yant0.csv'), process_csv_file('check_shapes/shape 0/Optimized Zant0.csv')))\n",
    "shape1 = np.hstack((process_csv_file('check_shapes/shape 1/Given Yant1.csv'), process_csv_file('check_shapes/shape 1/Given Zant1.csv')))\n",
    "shape1_opt = np.hstack((process_csv_file('check_shapes/shape 1/Optimized Yant1.csv'), process_csv_file('check_shapes/shape 1/Optimized Zant1.csv')))\n",
    "shape2 = np.hstack((process_csv_file('check_shapes/shape 2/Given Yant2.csv'), process_csv_file('check_shapes/shape 2/Given Zant2.csv')))\n",
    "shape2_opt = np.hstack((process_csv_file('check_shapes/shape 2/Optimized Yant2.csv'), process_csv_file('check_shapes/shape 2/Optimized Zant2.csv')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def pred_shape(model, inp, scale):\n",
    "    inp = torch.from_numpy(inp).float()\n",
    "    out = model(inp).detach().numpy()\n",
    "    return scale.inverse_transform(out.reshape(-1,1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-12610.568]\n",
      "[-21684.867]\n",
      "[-6103.668]\n",
      "[-17484.727]\n",
      "[-7413.79]\n",
      "[-20402.193]\n"
     ]
    }
   ],
   "source": [
    "print(pred_shape(model, shape0, scaler))\n",
    "print(pred_shape(model, shape0_opt, scaler))\n",
    "print(pred_shape(model, shape1, scaler))\n",
    "print(pred_shape(model, shape1_opt, scaler))\n",
    "print(pred_shape(model, shape2, scaler))\n",
    "print(pred_shape(model, shape2_opt, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_min_distance(ants, unit = 1):\n",
    "    \"\"\"\n",
    "    Checks the smallest Euclidean distance, if it violates then return True\n",
    "    \"\"\"\n",
    "    reshaped_tensor = torch.reshape(ants, (2, 1024))\n",
    "\n",
    "# Transpose the reshaped tensor\n",
    "    reshaped_tensor = torch.transpose(reshaped_tensor, 0, 1)\n",
    "    nonzero_rows = torch.any(reshaped_tensor != 0, dim=1)\n",
    "    filtered_tensor = reshaped_tensor[nonzero_rows]\n",
    "    distances = torch.cdist(filtered_tensor, filtered_tensor)\n",
    "    distances.fill_diagonal_(float('inf'))\n",
    "    closest_neighbor_distances, _ = torch.min(distances, dim=1)\n",
    "    smallest = torch.min(closest_neighbor_distances)\n",
    "    return smallest.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_wrt_input(model, ants, lr, noise_std, iters):\n",
    "    model.eval()\n",
    "    last = None\n",
    "    for i in range(iters):\n",
    "        if ants.grad is not None:\n",
    "            ants.requires_grad_()\n",
    "            ants.grad.zero_()\n",
    "        output = model(ants)\n",
    "        output.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            last = ants.clone()\n",
    "            noise = torch.rand_like(ants) * noise_std\n",
    "            ants -= (lr * ants.grad * (ants != 0).float())\n",
    "            if calculate_min_distance(ants) < 0.5:\n",
    "                continue\n",
    "        ants.grad.zero_()\n",
    "    return ants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_arrays(inp):\n",
    "    data = inp.cpu().detach().numpy()\n",
    "    reshaped_data = np.reshape(data, (2,1024))\n",
    "    x = reshaped_data[0]\n",
    "    y = reshaped_data[1]\n",
    "\n",
    "    nonzero_ind = np.nonzero((x != 0) | (y != 0))\n",
    "    x = x[nonzero_ind]\n",
    "    y = y[nonzero_ind]\n",
    "\n",
    "    plt.scatter(x,y, s=0.75)\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Antenna Array Pattern')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_shapes =  np.zeros((20, 2048))#pd.DataFrame(columns=[f'y{i + 1}' for i in range(1024)] + [f'z{i + 1}' for i in range(1024)])\n",
    "optimized_shapes = np.zeros((20, 2048)) #pd.DataFrame(columns=[f'y{i + 1}' for i in range(1024)] + [f'z{i + 1}' for i in range(1024)])\n",
    "given_shapes_True_cost = []\n",
    "given_shapes_pred_cost = []\n",
    "optimized_shapes_pred_cost = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(AntDataset('data/large/scaled_cost/YZ_Large_70_Cost_Scaled.npz'))\n",
    "i = 0\n",
    "for inp, out in train_loader:\n",
    "    if i == 20:\n",
    "        break\n",
    "\n",
    "    given_shapes_True_cost.append(out.item())\n",
    "    given_shapes[i, :] = inp.flatten().numpy()\n",
    "    inp, out = inp.to(device), out.to(device)\n",
    "\n",
    "    inp_copy = inp.clone()\n",
    "    inp_copy.requires_grad_()\n",
    "    print(f'True Cost: {out}')\n",
    "    show_arrays(inp)\n",
    "    inp.requires_grad_()\n",
    "    pred = model(inp)\n",
    "    given_shapes_pred_cost.append(pred.item())\n",
    "    print(f'Pred Cost: {pred}')\n",
    "    print(calculate_min_distance(inp))\n",
    "    optimized_inp = gradient_wrt_input(model, inp_copy,1e-2,1e-12, 10000)\n",
    "    optimized_shapes[i, :] = optimized_inp.detach().flatten().cpu().numpy()\n",
    "    optimized_inp.to(device)\n",
    "    new_pred = model(optimized_inp)\n",
    "    optimized_shapes_pred_cost.append(new_pred.item())\n",
    "    print(f'New Pred: {new_pred}')\n",
    "    show_arrays(optimized_inp)\n",
    "    print(optimized_inp.shape)\n",
    "    print(calculate_min_distance(optimized_inp))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'y{i + 1}' for i in range(1024)] + [f'z{i + 1}' for i in range(1024)]\n",
    "given_shapes_df = pd.DataFrame(given_shapes, columns=columns)\n",
    "optimized_shapes_df = pd.DataFrame(optimized_shapes, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_shapes_df.to_csv('given_shapes.csv', index = False)\n",
    "optimized_shapes_df.to_csv('optimized_shapes.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_shapes_true_cost_df = pd.DataFrame({'True Cost': given_shapes_True_cost})\n",
    "given_shapes_pred_cost_df = pd.DataFrame({'Predicted Cost': given_shapes_pred_cost})\n",
    "optimized_shapes_pred_cost_df = pd.DataFrame({'Optimized Predicted Cost': optimized_shapes_pred_cost})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_shapes_pred_cost_df.to_csv('given_shapes_pred_cost.csv', index = False)\n",
    "given_shapes_true_cost_df.to_csv('given_shapes_true_cost.csv', index = False)\n",
    "optimized_shapes_pred_cost_df.to_csv('optimized_shapes_pred_cost.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/large/large_YZant.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "small, large = np.load('data/large/scaled_cost/YZ_Large_30_Cost_Scaled.npz')['data'], np.load('data/large/scaled_cost/YZ_Large_70_Cost_Scaled.npz')['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.vstack((small, large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(stacked[:, -1])\n",
    "best_10 = stacked[indices[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-30.64484559, -29.70205211, -28.75925864, ...,   0.        ,\n",
       "          0.        ,  -3.21482132],\n",
       "       [-30.75978435, -29.21376344, -27.66774254, ...,   0.        ,\n",
       "          0.        ,  -3.15755776],\n",
       "       [-31.07106781, -29.65685425, -28.24264069, ...,   0.        ,\n",
       "          0.        ,  -3.13994073],\n",
       "       ...,\n",
       "       [-30.38340047, -28.72046124, -27.05752202, ...,   0.        ,\n",
       "          0.        ,  -3.02542015],\n",
       "       [-30.64484559, -29.70205211, -28.75925864, ...,   0.        ,\n",
       "          0.        ,  -3.02417421],\n",
       "       [-30.38340047, -28.72046124, -27.05752202, ...,   0.        ,\n",
       "          0.        ,  -3.01451864]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>...</th>\n",
       "      <th>z1016</th>\n",
       "      <th>z1017</th>\n",
       "      <th>z1018</th>\n",
       "      <th>z1019</th>\n",
       "      <th>z1020</th>\n",
       "      <th>z1021</th>\n",
       "      <th>z1022</th>\n",
       "      <th>z1023</th>\n",
       "      <th>z1024</th>\n",
       "      <th>True Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-30.644846</td>\n",
       "      <td>-29.702052</td>\n",
       "      <td>-28.759259</td>\n",
       "      <td>-30.766590</td>\n",
       "      <td>-29.823797</td>\n",
       "      <td>-28.881003</td>\n",
       "      <td>-27.938210</td>\n",
       "      <td>-26.995416</td>\n",
       "      <td>-26.052623</td>\n",
       "      <td>-29.945541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.214821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-30.759784</td>\n",
       "      <td>-29.213763</td>\n",
       "      <td>-27.667743</td>\n",
       "      <td>-31.037019</td>\n",
       "      <td>-29.490998</td>\n",
       "      <td>-27.944977</td>\n",
       "      <td>-26.398956</td>\n",
       "      <td>-24.852935</td>\n",
       "      <td>-23.306914</td>\n",
       "      <td>-29.768232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.157558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-31.071068</td>\n",
       "      <td>-29.656854</td>\n",
       "      <td>-28.242641</td>\n",
       "      <td>-26.828427</td>\n",
       "      <td>-31.071068</td>\n",
       "      <td>-29.656854</td>\n",
       "      <td>-28.242641</td>\n",
       "      <td>-26.828427</td>\n",
       "      <td>-25.414214</td>\n",
       "      <td>-24.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.139941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-30.759784</td>\n",
       "      <td>-29.213763</td>\n",
       "      <td>-27.667743</td>\n",
       "      <td>-31.037019</td>\n",
       "      <td>-29.490998</td>\n",
       "      <td>-27.944977</td>\n",
       "      <td>-26.398956</td>\n",
       "      <td>-24.852935</td>\n",
       "      <td>-23.306914</td>\n",
       "      <td>-29.768232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.108225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-30.759784</td>\n",
       "      <td>-29.213763</td>\n",
       "      <td>-27.667743</td>\n",
       "      <td>-31.037019</td>\n",
       "      <td>-29.490998</td>\n",
       "      <td>-27.944977</td>\n",
       "      <td>-26.398956</td>\n",
       "      <td>-24.852935</td>\n",
       "      <td>-23.306914</td>\n",
       "      <td>-29.768232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.103843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-29.945541</td>\n",
       "      <td>-28.181698</td>\n",
       "      <td>-26.417856</td>\n",
       "      <td>-30.766590</td>\n",
       "      <td>-29.002747</td>\n",
       "      <td>-27.238905</td>\n",
       "      <td>-25.475062</td>\n",
       "      <td>-23.711220</td>\n",
       "      <td>-21.947377</td>\n",
       "      <td>-29.823797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.098636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-30.383400</td>\n",
       "      <td>-28.720461</td>\n",
       "      <td>-27.057522</td>\n",
       "      <td>-30.935199</td>\n",
       "      <td>-29.272260</td>\n",
       "      <td>-27.609321</td>\n",
       "      <td>-25.946382</td>\n",
       "      <td>-24.283442</td>\n",
       "      <td>-22.620503</td>\n",
       "      <td>-29.824059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.061418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-30.383400</td>\n",
       "      <td>-28.720461</td>\n",
       "      <td>-27.057522</td>\n",
       "      <td>-30.935199</td>\n",
       "      <td>-29.272260</td>\n",
       "      <td>-27.609321</td>\n",
       "      <td>-25.946382</td>\n",
       "      <td>-24.283442</td>\n",
       "      <td>-22.620503</td>\n",
       "      <td>-29.824059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.025420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-30.644846</td>\n",
       "      <td>-29.702052</td>\n",
       "      <td>-28.759259</td>\n",
       "      <td>-30.766590</td>\n",
       "      <td>-29.823797</td>\n",
       "      <td>-28.881003</td>\n",
       "      <td>-27.938210</td>\n",
       "      <td>-26.995416</td>\n",
       "      <td>-26.052623</td>\n",
       "      <td>-29.945541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.024174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-30.383400</td>\n",
       "      <td>-28.720461</td>\n",
       "      <td>-27.057522</td>\n",
       "      <td>-30.935199</td>\n",
       "      <td>-29.272260</td>\n",
       "      <td>-27.609321</td>\n",
       "      <td>-25.946382</td>\n",
       "      <td>-24.283442</td>\n",
       "      <td>-22.620503</td>\n",
       "      <td>-29.824059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.014519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y1         y2         y3         y4         y5         y6  \\\n",
       "0 -30.644846 -29.702052 -28.759259 -30.766590 -29.823797 -28.881003   \n",
       "1 -30.759784 -29.213763 -27.667743 -31.037019 -29.490998 -27.944977   \n",
       "2 -31.071068 -29.656854 -28.242641 -26.828427 -31.071068 -29.656854   \n",
       "3 -30.759784 -29.213763 -27.667743 -31.037019 -29.490998 -27.944977   \n",
       "4 -30.759784 -29.213763 -27.667743 -31.037019 -29.490998 -27.944977   \n",
       "5 -29.945541 -28.181698 -26.417856 -30.766590 -29.002747 -27.238905   \n",
       "6 -30.383400 -28.720461 -27.057522 -30.935199 -29.272260 -27.609321   \n",
       "7 -30.383400 -28.720461 -27.057522 -30.935199 -29.272260 -27.609321   \n",
       "8 -30.644846 -29.702052 -28.759259 -30.766590 -29.823797 -28.881003   \n",
       "9 -30.383400 -28.720461 -27.057522 -30.935199 -29.272260 -27.609321   \n",
       "\n",
       "          y7         y8         y9        y10  ...  z1016  z1017  z1018  \\\n",
       "0 -27.938210 -26.995416 -26.052623 -29.945541  ...    0.0    0.0    0.0   \n",
       "1 -26.398956 -24.852935 -23.306914 -29.768232  ...    0.0    0.0    0.0   \n",
       "2 -28.242641 -26.828427 -25.414214 -24.000000  ...    0.0    0.0    0.0   \n",
       "3 -26.398956 -24.852935 -23.306914 -29.768232  ...    0.0    0.0    0.0   \n",
       "4 -26.398956 -24.852935 -23.306914 -29.768232  ...    0.0    0.0    0.0   \n",
       "5 -25.475062 -23.711220 -21.947377 -29.823797  ...    0.0    0.0    0.0   \n",
       "6 -25.946382 -24.283442 -22.620503 -29.824059  ...    0.0    0.0    0.0   \n",
       "7 -25.946382 -24.283442 -22.620503 -29.824059  ...    0.0    0.0    0.0   \n",
       "8 -27.938210 -26.995416 -26.052623 -29.945541  ...    0.0    0.0    0.0   \n",
       "9 -25.946382 -24.283442 -22.620503 -29.824059  ...    0.0    0.0    0.0   \n",
       "\n",
       "   z1019  z1020  z1021  z1022  z1023  z1024  True Cost  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0  -3.214821  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0  -3.157558  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0  -3.139941  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0  -3.108225  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0  -3.103843  \n",
       "5    0.0    0.0    0.0    0.0    0.0    0.0  -3.098636  \n",
       "6    0.0    0.0    0.0    0.0    0.0    0.0  -3.061418  \n",
       "7    0.0    0.0    0.0    0.0    0.0    0.0  -3.025420  \n",
       "8    0.0    0.0    0.0    0.0    0.0    0.0  -3.024174  \n",
       "9    0.0    0.0    0.0    0.0    0.0    0.0  -3.014519  \n",
       "\n",
       "[10 rows x 2049 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [f'y{i + 1}' for i in range(1024)] + [f'z{i + 1}' for i in range(1024)] + ['True Cost']\n",
    "top_10_arrays = pd.DataFrame(best_10, columns=columns)\n",
    "top_10_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_arrays.to_csv('top_10_arrays.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN2(\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=8, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0, inplace=False)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0, inplace=False)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = NN2(2048, 1, 8, 8, nn.ReLU)\n",
    "model.load_state_dict(torch.load('weights/NN2_CostScaled_8_8_ReLU.pth'))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_shapes =  np.zeros((10, 2048))#pd.DataFrame(columns=[f'y{i + 1}' for i in range(1024)] + [f'z{i + 1}' for i in range(1024)])\n",
    "optimized_shapes = np.zeros((10, 2048)) #pd.DataFrame(columns=[f'y{i + 1}' for i in range(1024)] + [f'z{i + 1}' for i in range(1024)])\n",
    "given_shapes_True_cost = []\n",
    "given_shapes_pred_cost = []\n",
    "optimized_shapes_pred_cost = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Cost: tensor([-3.2148], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.7861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-4.5998]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "True Cost: tensor([-3.1576], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.6941]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-3.9437]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "True Cost: tensor([-3.1399], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.7631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-3.7884]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "True Cost: tensor([-3.1082], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.8222]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-3.9638]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "True Cost: tensor([-3.1038], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.8985]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-4.1084]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "True Cost: tensor([-3.0986], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.7648]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-3.8906]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "True Cost: tensor([-3.0614], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.7784]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-3.8821]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "True Cost: tensor([-3.0254], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.4675]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-4.0319]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "True Cost: tensor([-3.0242], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.7254]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-3.7417]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "True Cost: tensor([-3.0145], device='cuda:0')\n",
      "Pred Cost: tensor([[-2.6493]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "New Pred: tensor([[-3.6109]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = DataLoader(AntDataset(best_10))\n",
    "i = 0\n",
    "for inp, out in train_loader:\n",
    "\n",
    "    given_shapes_True_cost.append(out.item())\n",
    "    given_shapes[i, :] = inp.flatten().numpy()\n",
    "    inp, out = inp.to(device), out.to(device)\n",
    "\n",
    "    inp_copy = inp.clone()\n",
    "    inp_copy.requires_grad_()\n",
    "    print(f'True Cost: {out}')\n",
    "    inp.requires_grad_()\n",
    "    pred = model(inp)\n",
    "    given_shapes_pred_cost.append(pred.item())\n",
    "    print(f'Pred Cost: {pred}')\n",
    "    optimized_inp = gradient_wrt_input(model, inp_copy,1e-2,1e-12, 10000)\n",
    "    optimized_shapes[i, :] = optimized_inp.detach().flatten().cpu().numpy()\n",
    "    optimized_inp.to(device)\n",
    "    new_pred = model(optimized_inp)\n",
    "    optimized_shapes_pred_cost.append(new_pred.item())\n",
    "    print(f'New Pred: {new_pred}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ba32117a522425853f495a8d3e20826e2647e023eb95fff9d9513e406ddf7d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
