{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Method 1: Standardize Y and Z separately\n",
    "For this method, we will have two CSV files, YantData_padded.csv and ZantData_padded.csv, both with 0 padding. The shape will be 9001x1024 for each CSV file. We will first combine them, then split the two into training and testing sets, then standardize by the column the YantData and the Zantdata separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.10114443e+01, -3.10081719e+01, -3.10048994e+01, ...,\n",
       "         2.89946535e+01,  3.09946529e+01, -7.88138739e-02],\n",
       "       [-3.10441054e+01, -3.09350764e+01, -3.08260473e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -9.74076214e-01],\n",
       "       [-3.10759402e+01, -3.10541240e+01, -3.10323078e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -9.13389276e-01],\n",
       "       ...,\n",
       "       [-3.06448456e+01, -2.97020521e+01, -2.87592586e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.17964143e+04],\n",
       "       [-2.96620436e+01, -2.76716742e+01, -2.56813047e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.89042961e+04],\n",
       "       [-3.10000000e+01, -3.10000000e+01, -3.10000000e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.08419570e+04]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('data/large/large_YZant.npz')['arr_0']\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Y and Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "Y = data[:, -1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.7, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.hstack((X_train, Y_train.reshape(-1, 1)))\n",
    "testing = np.hstack((X_test, Y_test.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('YZ_Large_training.npz', data = training)\n",
    "np.savez('YZ_Large_testing.npz', data = testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and concatenate the data with the target\n",
    "YantData = pd.read_csv('data/csv/YantData_padded.csv', header = None)\n",
    "ZantData = pd.read_csv('data/csv/ZantData_padded.csv', header = None)\n",
    "costData = pd.read_csv('data/csv/cost.csv', header = None)\n",
    "YZ_Labeled_antData = pd.concat([YantData, ZantData, costData], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "X = YZ_Labeled_antData.iloc[:, :-1]\n",
    "Y = YZ_Labeled_antData.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the Y and Z ant Data. Y ant will be the first 1024, Z will be the next 1024\n",
    "# Standardize them separately\n",
    "Yant_train, Zant_train = X_train.iloc[:, :1024], X_train.iloc[:, 1024:]\n",
    "\n",
    "# Create a scaler for Y which we can use for the test data set\n",
    "Yant_scaler = StandardScaler()\n",
    "Yant_scaler.fit(Yant_train)\n",
    "scaled_Yant_train = pd.DataFrame(Yant_scaler.transform(Yant_train))\n",
    "\n",
    "# Create a scaler for Z which we can use for the test data set\n",
    "Zant_scaler = StandardScaler()\n",
    "Zant_scaler.fit(Zant_train)\n",
    "scaled_Zant_train = pd.DataFrame(Zant_scaler.transform(Zant_train))\n",
    "\n",
    "cost_scaler = StandardScaler()\n",
    "# Need to reshape Y_train\n",
    "Y_train = Y_train.values.reshape(-1,1)\n",
    "cost_scaler.fit(Y_train)\n",
    "scaled_Cost_train = pd.DataFrame(cost_scaler.transform(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test data based on the scaler of the training\n",
    "Yant_test, Zant_test = X_test.iloc[:, :1024], X_test.iloc[:, 1024:]\n",
    "\n",
    "scaled_Yant_test = pd.DataFrame(Yant_scaler.transform(Yant_test))\n",
    "scaled_Zant_test = pd.DataFrame(Zant_scaler.transform(Zant_test))\n",
    "Y_test = Y_test.values.reshape(-1,1)\n",
    "scaled_Cost_test = pd.DataFrame(cost_scaler.transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the scaled Yant and Zant training together\n",
    "scaled_train_combine = pd.concat([scaled_Yant_train, scaled_Zant_train, scaled_Cost_train], axis = 1)\n",
    "\n",
    "# Combine the scaled Yant and Zant testing together\n",
    "scaled_test_combine = pd.concat([scaled_Yant_test, scaled_Zant_test, scaled_Cost_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both as separate CSV for future use\n",
    "# the suffix S denotes the method of separately standardizing Y and Z\n",
    "scaled_train_combine.to_csv('YZantData_train_standardized_S.csv', header = False, index = False)\n",
    "scaled_test_combine.to_csv('YZantData_test__standardized_S.csv', header = False, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Standardize Y and Z together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and concatenate the data with the target\n",
    "YantData = pd.read_csv('data/csv/YantData_padded.csv', header = None)\n",
    "ZantData = pd.read_csv('data/csv/ZantData_padded.csv', header = None)\n",
    "costData = pd.read_csv('data/csv/cost.csv', header = None)\n",
    "YZ_Labeled_antData = pd.concat([YantData, ZantData, costData], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "X = YZ_Labeled_antData.iloc[:, :-1]\n",
    "Y = YZ_Labeled_antData.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the Y and Z ant Data together\n",
    "YZant_scaler = StandardScaler()\n",
    "YZant_scaler.fit(X_train)\n",
    "scaled_YZant_train = pd.DataFrame(YZant_scaler.transform(X_train))\n",
    "\n",
    "cost_scaler = StandardScaler()\n",
    "# Need to reshape Y_train\n",
    "Y_train = Y_train.values.reshape(-1,1)\n",
    "cost_scaler.fit(Y_train)\n",
    "scaled_Cost_train = pd.DataFrame(cost_scaler.transform(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_YZant_test = pd.DataFrame(YZant_scaler.transform(X_test))\n",
    "Y_test = Y_test.values.reshape(-1, 1)\n",
    "scaled_Cost_test = pd.DataFrame(cost_scaler.transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_combine = pd.concat([scaled_YZant_train, scaled_Cost_train], axis = 1)\n",
    "scaled_test_combine = pd.concat([scaled_YZant_test, scaled_Cost_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_combine.to_csv('YZantData_train_standardized_T.csv', header = False, index = False)\n",
    "scaled_test_combine.to_csv('YZantData_test__standardized_T.csv', header = False, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: No standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "YantData = pd.read_csv('data/csv/YantData_padded.csv', header = None)\n",
    "ZantData = pd.read_csv('data/csv/ZantData_padded.csv', header = None)\n",
    "costData = pd.read_csv('data/csv/cost.csv', header = None)\n",
    "YZ_Labeled_antData = pd.concat([YantData, ZantData, costData], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "X = YZ_Labeled_antData.iloc[:, :-1]\n",
    "Y = YZ_Labeled_antData.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "YZantData_train = pd.concat([X_train, Y_train], axis = 1)\n",
    "YZantData_test = pd.concat([X_test, Y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "YZantData_train.to_csv('YZantData_train.csv', header = False, index = False)\n",
    "YZantData_test.to_csv('YZantData_test.csv', header = False, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YZ-paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and concatenate the data with the target\n",
    "YantData = pd.read_csv('data/csv/YantData_padded.csv', header = None)\n",
    "ZantData = pd.read_csv('data/csv/ZantData_padded.csv', header = None)\n",
    "costData = pd.read_csv('data/csv/cost.csv', header = None)\n",
    "YZ_Labeled_antData = pd.concat([YantData, ZantData, costData], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "X = YZ_Labeled_antData.iloc[:, :-1]\n",
    "Y = YZ_Labeled_antData.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the Y and Z ant Data. Y ant will be the first 1024, Z will be the next 1024\n",
    "# Standardize them separately\n",
    "Yant_train, Zant_train = X_train.iloc[:, :1024], X_train.iloc[:, 1024:]\n",
    "\n",
    "# Create a scaler for Y which we can use for the test data set\n",
    "Yant_scaler = StandardScaler()\n",
    "Yant_scaler.fit(Yant_train)\n",
    "scaled_Yant_train = pd.DataFrame(Yant_scaler.transform(Yant_train))\n",
    "\n",
    "# Create a scaler for Z which we can use for the test data set\n",
    "Zant_scaler = StandardScaler()\n",
    "Zant_scaler.fit(Zant_train)\n",
    "scaled_Zant_train = pd.DataFrame(Zant_scaler.transform(Zant_train))\n",
    "\n",
    "cost_scaler = StandardScaler()\n",
    "# Need to reshape Y_train\n",
    "Y_train = Y_train.values.reshape(-1,1)\n",
    "cost_scaler.fit(Y_train)\n",
    "scaled_Cost_train = pd.DataFrame(cost_scaler.transform(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test data based on the scaler of the training\n",
    "Yant_test, Zant_test = X_test.iloc[:, :1024], X_test.iloc[:, 1024:]\n",
    "\n",
    "scaled_Yant_test = pd.DataFrame(Yant_scaler.transform(Yant_test))\n",
    "scaled_Zant_test = pd.DataFrame(Zant_scaler.transform(Zant_test))\n",
    "Y_test = Y_test.values.reshape(-1,1)\n",
    "scaled_Cost_test = pd.DataFrame(cost_scaler.transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zigzag_combine(A, B):\n",
    "    # Check that A and B have the same shape\n",
    "    features = A.shape[1]\n",
    "    C = np.vstack((A[:,0], B[:,0])).T\n",
    "    \n",
    "    for i in range(1, features):\n",
    "        y = A[:,i].reshape(-1,1)\n",
    "        z = B[:,i].reshape(-1,1)\n",
    "        C = np.hstack((C,y,z))\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_train = pd.DataFrame(zigzag_combine(scaled_Yant_train.values, scaled_Zant_train.values))\n",
    "finalized_test = pd.DataFrame(zigzag_combine(scaled_Yant_test.values, scaled_Zant_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "YZ_pair_Train = pd.concat([finalized_train, scaled_Cost_train], axis = 1)\n",
    "YZ_pair_Test = pd.concat([finalized_test, scaled_Cost_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "YZ_pair_Train.to_csv('YZ_pair_Train.csv', header = False, index = False)\n",
    "YZ_pair_Test.to_csv('YZ_pair_Test.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ba32117a522425853f495a8d3e20826e2647e023eb95fff9d9513e406ddf7d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
