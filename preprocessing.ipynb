{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Method 1: Standardize Y and Z separately\n",
    "For this method, we will have two CSV files, YantData_padded.csv and ZantData_padded.csv, both with 0 padding. The shape will be 9001x1024 for each CSV file. We will first combine them, then split the two into training and testing sets, then standardize by the column the YantData and the Zantdata separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.Standard_Norm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exa = np.load('data/large/scaled/YZ_Large_S_70.npz')['data']\n",
    "exb = np.load('data/large/scaled_YZ_cost/YZ_Large_70_YZ_Cost_Scaled.npz')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2049, 2049, 2049, ..., 2049, 2049, 2049])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(exb, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.12958848],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.02097653],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -1.94697886],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.6139737 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.77345109],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -1.20429456]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exa[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('data/large/YZ_Large_70.npz')['data'].astype(np.float32)\n",
    "test = np.load('data/large/YZ_Large_30.npz')['data'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.0982899e+01, -3.0391901e+01, -2.9800901e+01, ...,\n",
       "         0.0000000e+00,  0.0000000e+00, -1.2131306e+04],\n",
       "       [-3.1050512e+01, -3.0617632e+01, -3.0184753e+01, ...,\n",
       "         0.0000000e+00,  0.0000000e+00, -7.5354755e+02],\n",
       "       [-3.0415333e+01, -2.9326056e+01, -2.8236776e+01, ...,\n",
       "         0.0000000e+00,  0.0000000e+00, -3.0103195e+04],\n",
       "       ...,\n",
       "       [-3.0562178e+01, -2.9562178e+01, -2.8562178e+01, ...,\n",
       "         0.0000000e+00,  0.0000000e+00, -1.6921316e+04],\n",
       "       [-3.0868576e+01, -3.0123409e+01, -2.9378244e+01, ...,\n",
       "         0.0000000e+00,  0.0000000e+00, -3.2012881e+03],\n",
       "       [-3.0670824e+01, -2.9747328e+01, -2.8823830e+01, ...,\n",
       "         0.0000000e+00,  0.0000000e+00, -2.2758906e+04]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ScaleYZCost()\n",
    "scaler.fit(train[:, :1024], train[:, 1024:-1], train[:, -1])\n",
    "stats = scaler.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = scaler.transform(train[:, :1024], train[:, 1024:-1], train[:, -1])\n",
    "scaled_test = scaler.transform(test[:, :1024], test[:, 1024:-1], test[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6882082 , -1.6560017 , -1.623795  , ...,  0.        ,\n",
       "         0.        , -0.16891465],\n",
       "       [-1.6918929 , -1.6683029 , -1.6447132 , ...,  0.        ,\n",
       "         0.        ,  1.0542485 ],\n",
       "       [-1.6572787 , -1.5979182 , -1.5385576 , ...,  0.        ,\n",
       "         0.        , -2.1009781 ],\n",
       "       ...,\n",
       "       [-1.6652809 , -1.6107857 , -1.5562904 , ...,  0.        ,\n",
       "         0.        , -0.6838636 ],\n",
       "       [-1.6819782 , -1.6413702 , -1.6007622 , ...,  0.        ,\n",
       "         0.        ,  0.79110473],\n",
       "       [-1.6712017 , -1.6208755 , -1.5705492 , ...,  0.        ,\n",
       "         0.        , -1.3114322 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('YZ_Large_70_YZ_Cost_Scaled.npz', data = scaled_train)\n",
    "np.savez('YZ_Large_30_YZ_Cost_Scaled.npz', data = scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = train[:, -1]\n",
    "scale = ScaleCost()\n",
    "scale.fit(cost)\n",
    "train_cost = scale.transform(train[:, -1])\n",
    "test_cost = scale.transform(test[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07881387389043745\n",
      "-40464.06810019469\n"
     ]
    }
   ],
   "source": [
    "print(np.max(cost))\n",
    "print(np.min(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9301.9143389709"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:, -1] = train_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:, -1] = test_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('YZ_Large_70_Cost_Scaled.npz', data = train)\n",
    "np.savez('YZ_Large_30_Cost_Scaled.npz', data = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/small/YZ_pair_Train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.10114443e+01, -3.10081719e+01, -3.10048994e+01, ...,\n",
       "         2.89946535e+01,  3.09946529e+01, -7.88138739e-02],\n",
       "       [-3.10441054e+01, -3.09350764e+01, -3.08260473e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -9.74076214e-01],\n",
       "       [-3.10759402e+01, -3.10541240e+01, -3.10323078e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -9.13389276e-01],\n",
       "       ...,\n",
       "       [-3.06448456e+01, -2.97020521e+01, -2.87592586e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.17964143e+04],\n",
       "       [-2.96620436e+01, -2.76716742e+01, -2.56813047e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.89042961e+04],\n",
       "       [-3.10000000e+01, -3.10000000e+01, -3.10000000e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.08419570e+04]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('data/large/large_YZant.npz')['arr_0']\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Y and Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "Y = data[:, -1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.7, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.hstack((X_train, Y_train.reshape(-1, 1)))\n",
    "testing = np.hstack((X_test, Y_test.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('YZ_Large_training.npz', data = training)\n",
    "np.savez('YZ_Large_testing.npz', data = testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and concatenate the data with the target\n",
    "YantData = pd.read_csv('data/csv/YantData_padded.csv', header = None)\n",
    "ZantData = pd.read_csv('data/csv/ZantData_padded.csv', header = None)\n",
    "costData = pd.read_csv('data/csv/cost.csv', header = None)\n",
    "YZ_Labeled_antData = pd.concat([YantData, ZantData, costData], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "X = YZ_Labeled_antData.iloc[:, :-1]\n",
    "Y = YZ_Labeled_antData.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the Y and Z ant Data. Y ant will be the first 1024, Z will be the next 1024\n",
    "# Standardize them separately\n",
    "Yant_train, Zant_train = X_train[:, :1024], X_train[:, 1024:]\n",
    "\n",
    "# Create a scaler for Y which we can use for the test data set\n",
    "Yant_scaler = StandardScaler()\n",
    "Yant_scaler.fit(Yant_train)\n",
    "scaled_Yant_train = pd.DataFrame(Yant_scaler.transform(Yant_train))\n",
    "\n",
    "# Create a scaler for Z which we can use for the test data set\n",
    "Zant_scaler = StandardScaler()\n",
    "Zant_scaler.fit(Zant_train)\n",
    "scaled_Zant_train = pd.DataFrame(Zant_scaler.transform(Zant_train))\n",
    "\n",
    "cost_scaler = StandardScaler()\n",
    "# Need to reshape Y_train\n",
    "Y_train = Y_train.reshape(-1,1)\n",
    "cost_scaler.fit(Y_train)\n",
    "scaled_Cost_train = pd.DataFrame(cost_scaler.transform(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-30.78799485, -30.08468896, -29.38138307, ...,   0.        ,\n",
       "         0.        ,   0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yant_scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test data based on the scaler of the training\n",
    "Yant_test, Zant_test = X_test.iloc[:, :1024], X_test.iloc[:, 1024:]\n",
    "\n",
    "scaled_Yant_test = pd.DataFrame(Yant_scaler.transform(Yant_test))\n",
    "scaled_Zant_test = pd.DataFrame(Zant_scaler.transform(Zant_test))\n",
    "Y_test = Y_test.values.reshape(-1,1)\n",
    "scaled_Cost_test = pd.DataFrame(cost_scaler.transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the scaled Yant and Zant training together\n",
    "scaled_train_combine = pd.concat([scaled_Yant_train, scaled_Zant_train, scaled_Cost_train], axis = 1)\n",
    "\n",
    "# Combine the scaled Yant and Zant testing together\n",
    "scaled_test_combine = pd.concat([scaled_Yant_test, scaled_Zant_test, scaled_Cost_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both as separate CSV for future use\n",
    "# the suffix S denotes the method of separately standardizing Y and Z\n",
    "scaled_train_combine.to_csv('YZantData_train_standardized_S.csv', header = False, index = False)\n",
    "scaled_test_combine.to_csv('YZantData_test__standardized_S.csv', header = False, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Standardize Y and Z together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/small/YZ_pair_Train.csv', header = None)\n",
    "X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and concatenate the data with the target\n",
    "YantData = pd.read_csv('data/csv/YantData_padded.csv', header = None)\n",
    "ZantData = pd.read_csv('data/csv/ZantData_padded.csv', header = None)\n",
    "costData = pd.read_csv('data/csv/cost.csv', header = None)\n",
    "YZ_Labeled_antData = pd.concat([YantData, ZantData, costData], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "X = YZ_Labeled_antData.iloc[:, :-1]\n",
    "Y = YZ_Labeled_antData.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the Y and Z ant Data together\n",
    "YZant_scaler = StandardScaler()\n",
    "YZant_scaler.fit(X_train)\n",
    "scaled_YZant_train = pd.DataFrame(YZant_scaler.transform(X_train))\n",
    "\n",
    "cost_scaler = StandardScaler()\n",
    "# Need to reshape Y_train\n",
    "Y_train = Y_train.values.reshape(-1,1)\n",
    "cost_scaler.fit(Y_train)\n",
    "scaled_Cost_train = pd.DataFrame(cost_scaler.transform(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_YZant_test = pd.DataFrame(YZant_scaler.transform(X_test))\n",
    "Y_test = Y_test.values.reshape(-1, 1)\n",
    "scaled_Cost_test = pd.DataFrame(cost_scaler.transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_combine = pd.concat([scaled_YZant_train, scaled_Cost_train], axis = 1)\n",
    "scaled_test_combine = pd.concat([scaled_YZant_test, scaled_Cost_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_combine.to_csv('YZantData_train_standardized_T.csv', header = False, index = False)\n",
    "scaled_test_combine.to_csv('YZantData_test__standardized_T.csv', header = False, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: No standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "YantData = pd.read_csv('data/csv/YantData_padded.csv', header = None)\n",
    "ZantData = pd.read_csv('data/csv/ZantData_padded.csv', header = None)\n",
    "costData = pd.read_csv('data/csv/cost.csv', header = None)\n",
    "YZ_Labeled_antData = pd.concat([YantData, ZantData, costData], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "X = YZ_Labeled_antData.iloc[:, :-1]\n",
    "Y = YZ_Labeled_antData.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "YZantData_train = pd.concat([X_train, Y_train], axis = 1)\n",
    "YZantData_test = pd.concat([X_test, Y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "YZantData_train.to_csv('YZantData_train.csv', header = False, index = False)\n",
    "YZantData_test.to_csv('YZantData_test.csv', header = False, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YZ-paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and concatenate the data with the target\n",
    "YantData = pd.read_csv('data/csv/YantData_padded.csv', header = None)\n",
    "ZantData = pd.read_csv('data/csv/ZantData_padded.csv', header = None)\n",
    "costData = pd.read_csv('data/csv/cost.csv', header = None)\n",
    "YZ_Labeled_antData = pd.concat([YantData, ZantData, costData], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "X = YZ_Labeled_antData.iloc[:, :-1]\n",
    "Y = YZ_Labeled_antData.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the Y and Z ant Data. Y ant will be the first 1024, Z will be the next 1024\n",
    "# Standardize them separately\n",
    "Yant_train, Zant_train = X_train.iloc[:, :1024], X_train.iloc[:, 1024:]\n",
    "\n",
    "# Create a scaler for Y which we can use for the test data set\n",
    "Yant_scaler = StandardScaler()\n",
    "Yant_scaler.fit(Yant_train)\n",
    "scaled_Yant_train = pd.DataFrame(Yant_scaler.transform(Yant_train))\n",
    "\n",
    "# Create a scaler for Z which we can use for the test data set\n",
    "Zant_scaler = StandardScaler()\n",
    "Zant_scaler.fit(Zant_train)\n",
    "scaled_Zant_train = pd.DataFrame(Zant_scaler.transform(Zant_train))\n",
    "\n",
    "cost_scaler = StandardScaler()\n",
    "# Need to reshape Y_train\n",
    "Y_train = Y_train.values.reshape(-1,1)\n",
    "cost_scaler.fit(Y_train)\n",
    "scaled_Cost_train = pd.DataFrame(cost_scaler.transform(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test data based on the scaler of the training\n",
    "Yant_test, Zant_test = X_test.iloc[:, :1024], X_test.iloc[:, 1024:]\n",
    "\n",
    "scaled_Yant_test = pd.DataFrame(Yant_scaler.transform(Yant_test))\n",
    "scaled_Zant_test = pd.DataFrame(Zant_scaler.transform(Zant_test))\n",
    "Y_test = Y_test.values.reshape(-1,1)\n",
    "scaled_Cost_test = pd.DataFrame(cost_scaler.transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zigzag_combine(A, B):\n",
    "    # Check that A and B have the same shape\n",
    "    features = A.shape[1]\n",
    "    C = np.vstack((A[:,0], B[:,0])).T\n",
    "    \n",
    "    for i in range(1, features):\n",
    "        y = A[:,i].reshape(-1,1)\n",
    "        z = B[:,i].reshape(-1,1)\n",
    "        C = np.hstack((C,y,z))\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_train = pd.DataFrame(zigzag_combine(scaled_Yant_train.values, scaled_Zant_train.values))\n",
    "finalized_test = pd.DataFrame(zigzag_combine(scaled_Yant_test.values, scaled_Zant_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "YZ_pair_Train = pd.concat([finalized_train, scaled_Cost_train], axis = 1)\n",
    "YZ_pair_Test = pd.concat([finalized_test, scaled_Cost_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "YZ_pair_Train.to_csv('YZ_pair_Train.csv', header = False, index = False)\n",
    "YZ_pair_Test.to_csv('YZ_pair_Test.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ba32117a522425853f495a8d3e20826e2647e023eb95fff9d9513e406ddf7d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
